{
    "desc_integrated_gradients": "This provides a more reliable measure of importance by considering not just the final input, but the entire path from a neutral 'blank' state to your specific prompt. It carefully adds up the contribution of each word, preventing misleading results and giving a truer picture of each token's influence.",
    "desc_occlusion": "This method tests each word's necessity by asking, 'What happens if this word is missing?' It temporarily hides (or 'occludes') each token from the input and measures how much the model's output changes. A high score means the word was critical for the result.",
    "desc_saliency": "This method reveals the model's initial 'gut reaction' to each input token. It highlights which words the model found most interesting or surprising, based on a direct and fast calculation of importance. Think of it as a quick look at the model's focus.",
    "unsupported_method_desc": "Description not available for this method.",
    "ai_expert_intro": "You are a world-class AI interpretability expert. Your task is to analyze an attribution heatmap and provide a comprehensive, easy-to-understand explanation for a non-technical audience.",
    "analysis_details": "Analysis Details",
    "method_being_used": "Method Used:",
    "prompt_analyzed": "Prompt Analyzed:",
    "full_generated_text": "Full Generated Text:",
    "method_specific_context": "Method-Specific Context",
    "instructions_for_analysis": "Instructions for Analysis",
    "instruction_part_1_header": "### High-Level Visual Overview",
    "instruction_part_1_desc": "In two to three sentences, provide a general summary of the patterns you see in the attached heatmap image. Describe the general location of the 'hot spots' (brightly colored areas) and what this visually implies about the model's focus. **For example, if the method is {method_name}, you might expect to see [describe expected pattern for this method].** Do not use generic descriptions. Base your analysis exclusively on the visual information in the image.",
    "instruction_synthesis_header": "### Synthesis of Key Findings",
    "instruction_synthesis_desc": "Following your high-level visual overview, create a brief narrative synthesis of the key findings from the data provided below. Structure your analysis into two paragraphs: **Strongest Individual Connections** and **Most Influential Tokens Overall**. In the first paragraph, explain the significance of the strongest individual token-to-token connections. In the second, discuss the input tokens that had the highest average influence on the entire generation, **making sure to refer to the full generated text provided above to explain *why* these tokens were so influential in shaping the final output.** Explain *why* certain tokens are influential in both contexts. **Do not add a summary at the end of your analysis**.",
    "instruction_color_coding": "Formatting Rule: When you mention an input token, format it exactly like this: <span style='color: #60a5fa;'>the_token_here</span>. When you mention a generated token, format it exactly like this: <span style='color: #fca5a5;'>the_token_here</span>. Do not deviate from this format.",
    "data_priority_instruction": "The following text block contains the pre-calculated key findings. Use this as the exclusive source of truth for your analysis.",
    "data_section_header": "## Pre-Calculated Analysis (Source of Truth)",
    "begin_analysis_now": "Begin your analysis now. Remember to follow the two-part structure (High-Level Visual Overview, then Synthesis of Key Findings) as described above.",
    "attr_page_title": "<i class='bi bi-search'></i> Attribution Analysis",
    "attr_page_desc": "This page uses token-level attribution methods to explain how different parts of your input prompt influence the generated output. Select a method, enter a prompt, and see which words were most important for the model's prediction.",
    "how_methods_work_expander": "How Attribution Methods Work",
    "saliency_method_title": "Saliency",
    "saliency_method_desc": "Measures importance by calculating the gradient of the output with respect to the input tokens. It's fast but can sometimes be noisy.",
    "saliency_step_1": "<strong>1. Generate Output:</strong> The model generates the next word, e.g., 'over', for the prompt 'The quick brown fox jumps'.",
    "saliency_step_2": "<strong>2. Calculate Gradients:</strong> It computes how much the probability of 'over' would change with a tiny nudge to each input word's embedding.",
    "saliency_step_3": "<strong>3. Assign Scores:</strong> Words that cause the biggest change (e.g., 'jumps') get the highest scores.",
    "ig_method_title": "Integrated Gradients",
    "ig_method_desc": "A more robust method that attributes the prediction to the inputs by integrating gradients along a path from a baseline (e.g., zero embedding) to the input.",
    "ig_step_1": "<strong>1. Create Path:</strong> It creates a smooth path from a 'blank' input to the full prompt, 'The quick brown fox jumps'.",
    "ig_step_2": "<strong>2. Compute Gradients Along Path:</strong> It calculates gradients for the output 'over' at many small steps along this path.",
    "ig_step_3": "<strong>3. Sum Gradients:</strong> It sums up all these small gradient values to get a reliable score for how much each word contributed to the output.",
    "occlusion_method_title": "Occlusion",
    "occlusion_method_desc": "A simple, intuitive method that measures importance by replacing each input token and seeing how much the output probability changes.",
    "occlusion_step_1": "<strong>1. Get Original Probability:</strong> The model generates 'over' with a certain probability.",
    "occlusion_step_2": "<strong>2. Replace Words:</strong> It systematically replaces each word (e.g., 'jumps') with a neutral token and re-runs the model.",
    "occlusion_step_3": "<strong>3. Measure Impact:</strong> If replacing 'jumps' causes the probability of 'over' to drop significantly, 'jumps' is considered very important.",
    "input_header": "<i class='bi bi-pencil-square'></i> Input & Settings",
    "enter_prompt": "Enter your prompt:",
    "enter_prompt_help": "Enter the text for the model to continue",
    "enable_ai_explanations": "Enable AI Explanations",
    "enable_ai_explanations_help": "Generate explanations for visualizations using Qwen 2.5 VL 72B (requires API access)",
    "generate_and_analyze_button": "Generate & Analyze All Methods",
    "max_new_tokens_slider": "Number of Tokens to Generate",
    "max_new_tokens_slider_help": "Controls the length of the generated text.",
    "loading_models_spinner": "Loading OLMo model with all attribution methods...",
    "generating_attributions_spinner": "Generating text and attributions...",
    "analysis_complete_success": "All attribution analyses complete!",
    "failed_to_generate_analysis_error": "Failed to generate analysis",
    "failed_to_load_models_error": "Failed to load models",
    "please_enter_prompt_warning": "Please enter a prompt",
    "output_header": "<i class='bi bi-display'></i> Output",
    "generated_text_subheader": "Generated Text",
    "input_label": "Input:",
    "generated_label": "Generated:",
    "attribution_analysis_results_header": "Attribution Analysis Results",
    "attr_tab": "Integrated Gradients",
    "occlusion_tab": "Occlusion",
    "saliency_tab": "Saliency",
    "attr_title": "Integrated Gradients Analysis",
    "occlusion_title": "Occlusion Analysis",
    "saliency_title": "Saliency Analysis",
    "attr_viz_desc": "**How to read this Integrated Gradients heatmap:**\\n- **X-axis**: Generated tokens (what the model produced)\\n- **Y-axis**: Input tokens (your original prompt)\\n- **Color intensity**: Mathematical gradient-based importance scores\\n- **Interpretation**: How much each input token mathematically influences each generated token",
    "occlusion_viz_desc": "Occlusion analysis highlights important tokens by temporarily masking (occluding) them and measuring the impact on the output. A larger attribution score means the token was more critical.",
    "saliency_viz_desc": "This visualization highlights the most salient tokens in the input that contributed to the generation.",
    "how_to_read_heatmap": "How to read this heatmap:",
    "xaxis_label": "X-axis",
    "xaxis_desc": "Generated tokens (what the model produced)",
    "yaxis_label": "Y-axis",
    "yaxis_desc": "Input tokens (your original prompt)",
    "color_intensity_label": "Color Intensity",
    "color_intensity_desc": "Mathematical importance scores",
    "interpretation_label": "Interpretation",
    "interpretation_desc": "How much each input token influences each generated token.",
    "special_tokens_label": "Special Tokens (e.g., `Ġ`, `Ċ`)",
    "special_tokens_desc": "These are artifacts from the tokenizer. Common ones include:<ul><li>`Ġ`: A space, marking a new word.</li><li>`Ċ`: A newline character.</li><li>`<|endoftext|>`: A special token marking the end of a sequence.</li></ul>",
    "creating_viz_spinner": "Creating {method_title} visualization...",
    "generating_ai_explanation_spinner": "Generating AI explanation for {method_title}...",
    "what_this_method_shows": "What this method shows:",
    "ai_generated_analysis": "AI Generated Analysis",
    "download_results_subheader": "Download Results",
    "download_html_button": "Download {method_title} HTML",
    "download_csv_button": "Download Scores (CSV)",
    "download_png_button": "Download {method_title} PNG",
    "heatmap_title": "Attribution Heatmap",
    "heatmap_xaxis": "Generated Tokens",
    "heatmap_yaxis": "Input Tokens",
    "feedback_survey_header": "Feedback & Comprehension Survey",
    "feedback_survey_desc": "Your feedback is valuable for improving this tool. Please take a moment to answer these questions.",
    "ux_feedback_subheader": "User Experience Feedback",
    "q_visual_clarity": "1. How would you rate the clarity of the heatmap visualizations?",
    "q_visual_clarity_help": "1 = Very Confusing, 5 = Very Clear",
    "q_cognitive_load": "2. How mentally demanding did you find it to interpret the results?",
    "q_cognitive_load_help": "1 = Not Demanding at all, 5 = Very Demanding",
    "q_influential_docs_plausibility": "3. How plausible are the 3 most influential documents identified by the Influence Tracer?",
    "q_influential_docs_plausibility_help": "1 = Not Plausible at all, 5 = Very Plausible",
    "comprehension_qs_subheader": "Quick Comprehension Check",
    "comprehension_qs_desc": "Based on the visualizations you just saw, which method best answers the following questions?",
    "q_options_ig": "Integrated Gradients",
    "q_options_occlusion": "Occlusion",
    "q_options_saliency": "Saliency",
    "q_s1": "Which method reveals the model's initial 'gut reaction' to each word, showing its most direct and immediate focus?",
    "q_s2": "Which method would you use to understand the impact of removing a specific word?",
    "q_s3": "Which method builds a more reliable picture of importance by analyzing the entire path from a blank input to your final prompt?",
    "submit_feedback_button": "Submit Feedback",
    "feedback_success_message": "Thank you for your feedback!",
    "feedback_error_message": "Sorry, there was an error submitting your feedback: {e}",
    "feedback_please_answer_all_qs": "Please answer all comprehension questions before submitting.",
    "error_creating_heatmap": "Error creating heatmap from HTML: {e}",
    "error_inseq_no_html": "Inseq failed to generate HTML output for {method_name}.",
    "error_no_table_in_html": "Could not find data table in inseq's HTML output for {method_name}.",
    "error_table_no_rows": "Table in HTML output contains no rows for {method_name}.",
    "error_failed_to_parse_rows": "Failed to parse any data rows from the HTML for {method_name}.",
    "running_influence_trace_spinner": "Tracing influences in the training data...",
    "influence_index_not_found_warning": "Influence tracer index not found. Skipping this step. Please run `build_dolma_index.py` to enable it.",
    "influence_tracer_title": "Influence Tracer",
    "influence_tracer_desc": "This tool identifies training documents from a sample of the <b>Dolma v1.6 dataset</b> that were most influential on the model's output. Dolma v1.6 is a 3-trillion-token open dataset composed of a diverse mix of web content (Common Crawl), academic publications (C4, arXiv), code (The Stack), books (Project Gutenberg), and encyclopedic data (Wikipedia). By tracing the model's generation back to its training data, we can better understand its reasoning and knowledge sources.",
    "top_influential_docs_header": "Top {num_docs} Most Influential Training Documents",
    "no_influential_docs_found": "No influential documents were found for this generation.",
    "file_label": "File",
    "source_label": "Source",
    "similarity_label": "Similarity",
    "run_analysis_for_influence_info": "Run an analysis to see influential training documents here.",
    "prompt_placeholder_text": "e.g., 'The capital of France is' or 'To be or not to be, that is the'",
    "running_attribution_analysis_spinner": "Generating attribution heatmaps...",
    "generating_ai_explanations_spinner": "Generating AI explanations...",
    "how_influence_is_found_header": "How Influence is Found: A Look at Cosine Similarity",
    "how_influence_is_found_desc": "The Influence Tracer doesn't just search for keywords; it searches for meaning. It does this by converting both your prompt and every sentence in the training data into high-dimensional vectors. It then uses a technique called <strong>Cosine Similarity</strong> to find the closest matches.",
    "influence_step_1_title": "<strong>1. Vector Conversion</strong>",
    "influence_step_1_desc": "Your prompt and each sentence from the training data are transformed into numerical vectors.",
    "influence_step_2_title": "<strong>2. Angle Calculation</strong>",
    "influence_step_2_desc": "The system calculates the angle (θ) between your prompt's vector and every other sentence vector.",
    "influence_step_3_title": "<strong>3. Similarity Score</strong>",
    "influence_step_3_desc": "A smaller angle means a higher similarity. A score of 1 means the sentences are identical in meaning, while a score of 0 means they are completely unrelated.",
    "influence_example_sentence_a": "Your Prompt",
    "influence_example_sentence_b": "Training Sentence",
    "generating_all_visualizations_spinner": "Generating all visualizations and AI explanations...",
    "searching_influential_docs_progress": "Searching for influential documents...",
    "processing_doc_progress": "Processing document {i} of {k}...",
    "search_complete_progress": "Search complete!",
    "faithfulness_check_expander": "Faithfulness Check",
    "running_faithfulness_check_spinner": "Running faithfulness check...",
    "verified_status": "Verified",
    "contradicted_status": "Contradicted",
    "claim_label": "Claim",
    "status_label": "Status",
    "evidence_label": "Evidence",
    "no_verifiable_claims_info": "No verifiable claims were extracted from the explanation.",
    "faithfulness_check_error": "An error occurred during the faithfulness check: {e}",
    "faithfulness_check_results_header": "Faithfulness Check Results:",
    "faithfulness_check_explanation_html": "<div style='font-size: 0.9rem; color: #DCDCDC; margin-bottom: 1rem;'><p style='margin-bottom: 0.5rem;'><strong>How This Works:</strong> The faithfulness checker verifies two types of claims from the AI's explanation:</p><ul style='margin-left: 1.5rem; padding-left: 0; list-style-type: disc;'><li style='margin-bottom: 0.3rem;'><strong>Numerical Claims:</strong> Checks if a token's attribution score (either its peak 'hotspot' or its average score) meets a dynamic threshold.<ul style='margin-left: 1.5rem; padding-left: 0; list-style-type: circle;'><li>A <strong>\"high\"</strong> claim (e.g., \"highest,\" \"strongest\") must be above <strong>70%</strong> of the maximum score in the analysis.</li><li>A <strong>\"significant\"</strong> claim (e.g., \"notable\") must be above <strong>50%</strong> of the maximum score.</li></ul></li><li style='margin-bottom: 0.3rem;'><strong>Justification Claims:</strong> Uses another AI to semantically analyze whether the <strong>reasoning</strong> provided for a token's importance is plausible and logically consistent.</li></ul></div>",
    "claim_extraction_prompt_header": "You are an expert claim extraction system. Your task is to read an explanation of a text attribution analysis and extract all verifiable, factual claims into a structured JSON list. A single sentence may contain multiple distinct claims.",
    "claim_extraction_prompt_instruction": "Each object in the list MUST have the following keys:\n1. `claim_text`: The exact sentence or phrase from the explanation that makes the claim.\n2. `claim_type`: One of the available claim types.\n3. `details`: An object containing the specific parameters for verification.",
    "claim_extraction_prompt_context_header": "**Analysis Method Context:** {analysis_method}",
    "claim_extraction_prompt_types_header": "**Available Claim Types:**",
    "claim_extraction_prompt_types_details": "- `attribution_claim`: A claim that one or more tokens have high or significant attribution scores, either based on their peak (hotspot) or average influence.\n  - `details`: {{ \"tokens\": [\"...\"], \"qualifier\": \"high\" | \"significant\", \"score_type\": \"peak\" | \"average\" }}\n  - **Note:** Use \"peak\" for claims about hotspots or specific connections. Use \"average\" for claims about overall or average influence.\n- `token_justification_claim`: A claim that provides a specific reason for one or more tokens' importance or attribution score.\n  - `details`: {{ \"tokens\": [\"...\"], \"justification\": \"...\" }}",
    "claim_extraction_prompt_example_header": "**Example:**",
    "claim_extraction_prompt_example_explanation": "- **Explanation sentence:** \"Overall, 'France' has the highest average influence, while '.' has a significant peak score.\"",
    "claim_extraction_prompt_example_json": "- **Resulting JSON object:**\n  ```json\n  [\n    {{\n      \"claim_text\": \"Overall, 'France' has the highest average influence...\",\n      \"claim_type\": \"attribution_claim\",\n      \"details\": {{ \"tokens\": [\"France\"], \"qualifier\": \"high\", \"score_type\": \"average\" }}\n    }},\n    {{\n      \"claim_text\": \"...while '.' has a significant peak score.\",\n      \"claim_type\": \"attribution_claim\",\n      \"details\": {{ \"tokens\": [\".\"], \"qualifier\": \"significant\", \"score_type\": \"peak\" }}\n    }}\n  ]\n  ```",
    "claim_extraction_prompt_analyze_header": "**Explanation to Analyze:**",
    "claim_extraction_prompt_instruction_footer": "Respond with ONLY the JSON list of claims.",
    "justification_verification_prompt_collective_reasoning": "**Collective Reasoning:** The justification may refer to multiple tokens at once (e.g., 'these tokens collectively...'). When evaluating such a claim, consider the group of tokens as a single unit and assess if the justification is plausible for them as a whole, even if it doesn't apply perfectly to each token individually.",
    "justification_verification_prompt_header": "You are an AI fact-checker specializing in NLP and semantic reasoning. Your task is to determine if a justification for a token's importance is plausible and logically consistent, given the full context.",
    "justification_verification_prompt_crucial_rule": "**Crucial Rule:** A justification is plausible if it presents a reasonable, creative, or contextually relevant connection. Only contradict if the reasoning is completely illogical, factually incorrect, or inconsistent with the given input or output text.",
    "justification_verification_prompt_token_location": "**Token Location:** The \"Token in Question\" can be from either the \"Input Prompt\" or the \"Generated Text\". A token from the input can still have a crucial influence on the generated output. Do not contradict a claim simply because the token is not present in the generated text.",
    "justification_verification_prompt_special_tokens": "**Special Tokens:** The 'Token in Question' may contain special characters from the tokenizer. `Ġ` represents a leading space (e.g., `Ġof` is ` of`), and suffixes like ` (1)` are for uniqueness (e.g., `. (1)` is just `.`). You MUST account for these when checking if a token exists in the text.",
    "justification_verification_prompt_evaluating_justifications": "**Evaluating Justifications:** A justification should be considered plausible if it identifies a reasonable connection, even if it is not a direct or simple causal link. This includes relationships based on the broader context of the text or the grammatical structure of the language. Pay special attention to tokens that form common collocations, entities, or abbreviations; connections between such tokens should be considered plausible as they are often processed as a single semantic unit by the model.",
    "justification_verification_prompt_linguistic_context": "**Linguistic Context for Autoregressive Models:** It is crucial to remember that in autoregressive models like this one, EVERY token directly influences the probability of the next token. Therefore, justifications based on grammatical structure, punctuation, or syntactic roles are not just valid, but represent a core part of the model's decision-making process. A token's structural role (like a preposition or a period) is a direct and important contributor to content generation. Do not dismiss these justifications as 'mere grammar'.",
    "justification_verification_prompt_task_header": "**Your Task:**",
    "justification_verification_prompt_task_instruction": "Based on the rule above, is the justification plausible?",
    "justification_verification_prompt_json_instruction": "Respond with a JSON object with two keys:\n1. `is_verified`: boolean (true if the justification is plausible, false if it is illogical or incorrect).\n2. `reasoning`: A brief, one-sentence explanation for your decision.",
    "justification_verification_prompt_footer": "Respond with ONLY the JSON object."
} 
