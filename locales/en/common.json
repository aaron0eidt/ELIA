{
    "llm_analysis_suite": "Explainable Language Interpretability Analysis Tool",
    "main_menu": "Main Menu",
    "attribution_analysis": "Attribution Analysis",
    "function_vectors": "Function Vectors",
    "circuit_tracing": "Circuit Tracing",
    "language": "Language",
    "unable_to_generate_explanation": "Unable to generate explanation at this time.",
    "clear_cache_button": "Clear Cache & Rerun",
    "q_influential_docs_plausibility_help": "How plausible did you find the documents identified by the Influence Tracer? (1=Not plausible, 5=Very plausible)",
    "comprehension_qs_subheader": "Comprehension Questions",
    "comprehension_qs_desc": "Please answer the following questions to the best of your ability based on your understanding of the visualizations.",
    "submit_feedback_button": "Submit Feedback",
    "feedback_success_message": "Thank you, your feedback has been submitted!",
    "feedback_please_answer_all_qs": "Please answer all comprehension questions before submitting.",

    "what_is_this_function_type": "What is this function type?",
    "desc_abstractive_tasks": "These tasks require the model to generate new text that captures the essence of the source text, rather than just extracting parts of it. Examples include summarization or paraphrasing.",
    "desc_multiple_choice_qa": "The model is given a question and a set of options, and it must choose the correct answer from the list. This tests reasoning and comprehension over a fixed set of choices.",
    "desc_text_classification": "The model must assign a predefined category or label to a piece of text. Common examples include sentiment analysis (positive/negative), topic classification, or spam detection.",
    "desc_extractive_tasks": "These tasks involve identifying and extracting a specific span of text directly from a given context. This is often used for question answering where the answer is explicitly stated in the text.",
    "desc_named_entity_recognition": "A sub-task of extractive tasks where the model identifies and categorizes named entities such as people, organizations, locations, dates, and other specific terms in text.",
    "desc_text_generation": "Open-ended text creation tasks where the model generates creative, coherent, or contextually appropriate text based on a prompt. Examples include writing a story, a poem, or continuing a paragraph.",

    "likert_scale_meaning": "1 = Strongly Disagree/Not at all Clear, 5 = Strongly Agree/Very Clear",
    "q1_pca_clarity": "How clear was the 3D PCA visualization?",
    "q2_type_attribution_clarity": "How clear was the Function Type Attribution bar chart?",
    "q_layer_evolution_plausibility": "How plausible did you find the Layer Evolution analysis (the way function changes across layers)?",

    "ct_q_main_graph_clarity": "How clear was the main circuit graph visualization for understanding the overall information flow?",
    "ct_q_feature_explorer_usefulness": "How useful was the Feature Explorer for understanding individual components?",
    "ct_q_subnetwork_clarity": "How helpful was the Subnetwork view for tracing specific pathways?",
    "ct_q1": "What is the primary role of the EARLY layers (e.g., 0-10) in circuit tracing?",
    "ct_q1_option_a": "To synthesize final concepts and make complex decisions.",
    "ct_q1_option_b": "To process basic patterns like syntax and word order from the input text.",
    "ct_q1_option_c": "To link abstract ideas from different parts of the prompt together.",
    "ct_q2": "What is the primary benefit of using the **Subnetwork Explorer** to focus on a single feature?",
    "ct_q2_option_a": "To see all features in the model at once.",
    "ct_q2_option_b": "To understand the local computational role of a feature by seeing its direct causes (inputs) and effects (outputs).",
    "ct_q2_option_c": "To change the color and size of the nodes in the graph.",
    "ct_q3": "If an early-layer feature (e.g., detecting syntax) strongly connects to a late-layer feature (e.g., identifying a concept), what does this pathway likely represent?",
    "ct_q3_option_a": "The model using foundational grammar to build a more abstract, conceptual understanding.",
    "ct_q3_option_b": "A random, meaningless connection that should be ignored.",
    "ct_q3_option_c": "The model only paying attention to the final layers and ignoring early ones."
} 